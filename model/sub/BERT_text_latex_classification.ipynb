{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6leHmF8x0fV"
   },
   "source": [
    "## 사전설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from imbalanced-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FVDGgqysxcVA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (4.31.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.conda/envs/team_conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 07:20:53.925020: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-04 07:20:54.572962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizer, DonutProcessor\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob, shutil\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Union, Tuple, Any\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 메인 모델 분들이 다 쓰신 후에 device 셀 실행!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9DaykCGKxfzU"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R7rsV6X20VxY"
   },
   "outputs": [],
   "source": [
    "LATEX_START = \"<latex>\"\n",
    "LATEX_END = \"</latex>\"\n",
    "\n",
    "new_tokens = [\n",
    "    LATEX_START,\n",
    "    LATEX_END\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQdOR30Ux3pR"
   },
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XrLgc39Lx4zZ"
   },
   "outputs": [],
   "source": [
    "train_json_files = glob.glob('./data/train/annotations/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u6IsAsFsHiwy"
   },
   "outputs": [],
   "source": [
    "test_json_files = glob.glob('./data/test/annotations/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKrR6qUQQSqG"
   },
   "source": [
    "## Training\n",
    "- `Donut_MathOCR` 의 Tokenizer 로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7695,
     "status": "ok",
     "timestamp": 1689950493458,
     "user": {
      "displayName": "전현욱",
      "userId": "16513256288302189921"
     },
     "user_tz": -540
    },
    "id": "gktQJ5jBpTRo",
    "outputId": "e098646b-c54e-4ed9-8b85-3ef8d0e94c36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150450/150450 [00:11<00:00, 12624.22it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_gt_string(files):\n",
    "    ground_truths = []\n",
    "    labels = []\n",
    "\n",
    "    for f in tqdm(files):\n",
    "        filename = os.path.basename(f)\n",
    "        filepath = Path(f)\n",
    "        \n",
    "        \n",
    "        with open(filepath,encoding='utf-8') as fp:\n",
    "            data = json.load(fp)\n",
    "            \n",
    "        label = filename.split('_')[2]\n",
    "        data_series = data['segments']\n",
    "\n",
    "        all_lines = []\n",
    "\n",
    "        NON_OBJECT = False\n",
    "        \n",
    "\n",
    "        for d_line in data_series:\n",
    "            if 'equation' not in d_line:\n",
    "                NON_OBJECT = True\n",
    "                break\n",
    "\n",
    "            if '$' not in d_line['equation']:\n",
    "                new_line = d_line['equation']\n",
    "            else:\n",
    "                equation = d_line['equation'].split('$')\n",
    "                latex_line = equation[0]\n",
    "                for i, e in enumerate(equation[1:]):\n",
    "                    if i%2 == 0:\n",
    "                        latex_line += LATEX_START + e\n",
    "                    else:\n",
    "                        latex_line += LATEX_END + e\n",
    "\n",
    "                new_line = latex_line\n",
    "        \n",
    "        all_lines.append(new_line)\n",
    "\n",
    "        if not NON_OBJECT:\n",
    "            ground_truths += all_lines\n",
    "            labels += [label] * len(all_lines)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return ground_truths, labels\n",
    "\n",
    "ground_truths, gt_labels = get_gt_string(train_json_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1689950494086,
     "user": {
      "displayName": "전현욱",
      "userId": "16513256288302189921"
     },
     "user_tz": -540
    },
    "id": "-RQpoyMOuYnA",
    "outputId": "aac5a7dd-c96c-4a58-acbc-5eb268b5d94f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_df = pd.DataFrame(gt_labels)\n",
    "label_df.value_counts().plot(kind='bar')\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1YJSBiJqQUvA"
   },
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'e4','e5','e6',\n",
    "    'm1','m2','m3',\n",
    "    'h1','h2','h3'\n",
    "]\n",
    "\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "\n",
    "for i, item in enumerate(labels):\n",
    "    id2label[i] = item\n",
    "    label2id[item] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processor 선택\n",
    "1. 메인 모델 토크나이저\n",
    "2. 한국어 기반 토크나이저 (bert-kor-base)\n",
    "3. 한국어-영어 토크나이저 (ke_t5_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#메인 모델 토크나이저\n",
    "processor = DonutProcessor.from_pretrained(\"./pretrained/main/epoch-3, batch-8, img_size-480, max_length-256, line_len/processor\")\n",
    "tokenizer = processor.tokenizer\n",
    "    \n",
    "#한국어 기반 토크나이저\n",
    "#BertTokenizerFast.from_pretrained(\"kykim/bert-kor-base\")\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#tokenizer_name='kor_base'\n",
    "\n",
    "#t5\n",
    "#model_name = 'KETI-AIR/ke-t5-base'\n",
    "#tokenizer = processor.T5Tokenizer.from_pretrained(model_name)\n",
    "#tokenizer_name='ke_t5_base'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 메인 모델 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4LOQWDyKvK3j",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁다음', '▁두', '▁', '식을', '▁모두', '▁만', '족', '시', '키', '는', '▁자연', '수']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize('다음 두 식을 모두 만족시키는 자연수'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bert-kor-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(tokenizer.tokenize('다음 두 식을 모두 만족시키는 자연수'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ke_t5_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(tokenizer.tokenize('다음 두 식을 모두 만족시키는 자연수'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_unk(texts):\n",
    "    ids = tokenizer(texts).input_ids\n",
    "    tokens = [tokenizer.tokenize(x) for x in texts]\n",
    "\n",
    "    unk_tokens = []\n",
    "    for example_ids, example_tokens in zip(ids, tokens):\n",
    "        example_unk_tokens = []\n",
    "        for i in range(len(example_ids)):\n",
    "            if example_ids[i] == tokenizer.unk_token_id:\n",
    "                try:\n",
    "                    example_unk_tokens.append(example_tokens[i])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        unk_tokens += example_unk_tokens\n",
    "\n",
    "    return unk_tokens\n",
    "\n",
    "unk_tokens = check_for_unk(cleaned_ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DFr3Q5UZrpXT",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "text_unk_tokens = list(set(unk_tokens))\n",
    "print(len(text_unk_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "snpbyz2v2m5u",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tokens added\n"
     ]
    }
   ],
   "source": [
    "#메인 모델 토큰 추가하기\n",
    "num_added = tokenizer.add_tokens(['[CLS]', '[SEP]'])\n",
    "print(num_added, \"tokens added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_ground_truths[:]\n",
    "y = cleaned_labels[:]\n",
    "\n",
    "\n",
    "X_bert = ['[CLS] ' + str(s) + ' [SEP]' for s in X]\n",
    "tokenized_texts = [tokenizer.tokenize(s) for s in X_bert]\n",
    "y = [label2id[x] for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max([len(x) for x in tokenized_texts])\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22590/22590 [00:00<00:00, 28162.13it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 레이블 불균형 --> 소수의 레이블 갯수에 맞춰서 균형화\n",
    "\n",
    "sampler=imblearn.under_sampling.RandomUnderSampler()\n",
    "under_inputs_id,under_y=sampler.fit_resample(input_ids,y)\n",
    "\n",
    "attention_masks = []\n",
    "\n",
    "for seq in tqdm(under_inputs_id):\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(under_inputs_id,under_y, random_state=42, test_size=0.1)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks,\n",
    "                                                       under_inputs_id,\n",
    "                                                       random_state=42,\n",
    "                                                       test_size=0.1)\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LVwRKN1fUnpE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ya_SQntU0NkC"
   },
   "outputs": [],
   "source": [
    "config = BertConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_position_embeddings=512,\n",
    "    num_labels=9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-6TXNoh-RdJY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 변경 후 처음 학습 할때\n",
    "#model = BertForSequenceClassification(config=config)\n",
    "\n",
    "#첫 학습 후 추가 학습할떄\n",
    "model =BertForSequenceClassification.from_pretrained(\"kykim/bert-kor-base\",num_labels=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Z5chxBahSCu2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(60016, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "J_WqU1OE42s7"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "vVu2OUC6Ril-"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8\n",
    "                )\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 3,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Qdx35nMARknj"
   },
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "v78HaWgpRlzL",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch \"1\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:50<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.93  Validation Accuracy: 0.39\n",
      " Validation Accuracy: 0.39\n",
      "Epoch \"2\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:35<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.60  Validation Accuracy: 0.43\n",
      " Validation Accuracy: 0.43\n",
      "Epoch \"3\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:35<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.47  Validation Accuracy: 0.47\n",
      " Validation Accuracy: 0.47\n",
      "Epoch \"4\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:35<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.37  Validation Accuracy: 0.50\n",
      " Validation Accuracy: 0.50\n",
      "Epoch \"5\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:35<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.29  Validation Accuracy: 0.51\n",
      " Validation Accuracy: 0.51\n",
      "Epoch \"6\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:35<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.23  Validation Accuracy: 0.51\n",
      " Validation Accuracy: 0.51\n",
      "Epoch \"7\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:35<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.18  Validation Accuracy: 0.52\n",
      " Validation Accuracy: 0.52\n",
      "Epoch \"8\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:35<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.14  Validation Accuracy: 0.53\n",
      " Validation Accuracy: 0.53\n",
      "Epoch \"9\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:35<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.12  Validation Accuracy: 0.52\n",
      " Validation Accuracy: 0.52\n",
      "Epoch \"10\": "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 509/509 [01:35<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average training loss: 1.11  Validation Accuracy: 0.52\n",
      " Validation Accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "\n",
    "model.zero_grad()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch \"{epoch + 1}\":', end=\" \")\n",
    "\n",
    "    total_loss = 0\n",
    "    model.train()  # Training 모드\n",
    "\n",
    "    # Batch 단위로 학습\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        \n",
    "        batch = tuple(t.to(device) for t in batch) \n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Loss 계산\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "       \n",
    "        loss.backward()\n",
    "\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) \n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step() \n",
    "\n",
    "        # 모델 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 Loss 출력\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\" Average training loss: {0:.2f}\".format(avg_train_loss), end=\" \")\n",
    "    \n",
    "    \n",
    "    model.eval()  # Validation 모드\n",
    "\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Batch 단위로 Validation 진행\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # 결과 처리\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Accuracy 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Validation Accuracy 출력\n",
    "    print(\" Validation Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\" Validation Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "9zvtDCycQw1V"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('./pretrained/Sub/prepro-epoch-10, batch-40, max_length-512, kykim-BERT-model')\n",
    "tokenizer.save_pretrained('./pretrained/Sub/prepro-epoch-10, batch-40, max_length-512, kykim-pre-BERT-model-tokenizer')\n",
    "config.save_pretrained('./pretrained/Sub/prepro-epoch-10, batch-40, max_length-512, kykim-pre-BERT-model-config')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkj7T43vIKFZ"
   },
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxxojGxVZrdr"
   },
   "source": [
    "For Few Sequencces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18728/18728 [00:00<00:00, 180595.11it/s]\n"
     ]
    }
   ],
   "source": [
    "paths=[]\n",
    "count=0\n",
    "for f in tqdm(test_json_files):\n",
    "    filename = os.path.basename(f)\n",
    "    filepath = Path(f)\n",
    "    file_str=str(filepath)\n",
    "    count+=1\n",
    "    if file_str.find('.zip')!= -1:\n",
    "        print(file_str,count)\n",
    "        pass\n",
    "    else:\n",
    "        paths.append(file_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_test_texts = []\n",
    "gt_test_labels = []\n",
    "\n",
    "for filepath in paths:\n",
    "    with open(Path(filepath),'r',encoding='utf-8') as fp:\n",
    "        data = json.load(fp)\n",
    "            \n",
    "    label = filename.split('_')[2]\n",
    "    data_series = data['segments']\n",
    "\n",
    "    all_lines = []\n",
    "\n",
    "    NON_OBJECT = False\n",
    "        \n",
    "\n",
    "    for d_line in data_series:\n",
    "        if 'equation' not in d_line:\n",
    "            NON_OBJECT = True\n",
    "            break\n",
    "\n",
    "        if '$' not in d_line['equation']:\n",
    "            new_line = d_line['equation']\n",
    "        else:\n",
    "            equation = d_line['equation'].split('$')\n",
    "            latex_line = equation[0]\n",
    "            for i, e in enumerate(equation[1:]):\n",
    "                if i%2 == 0:\n",
    "                    latex_line += LATEX_START + e\n",
    "                else:\n",
    "                    latex_line += LATEX_END + e\n",
    "\n",
    "            new_line = latex_line\n",
    "        \n",
    "        all_lines.append(new_line)\n",
    "\n",
    "    if not NON_OBJECT:\n",
    "        gt_test_texts += all_lines\n",
    "        gt_test_labels += [label] * len(all_lines)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'m3': 31720})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(gt_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "cxCWWimUIhYu"
   },
   "outputs": [],
   "source": [
    "def seqs2input(seqs, labels, MAX_LEN):\n",
    "    seq_bert = ['[CLS] ' + str(seq) + ' [SEP]' for seq in seqs]\n",
    "    tokenized_texts = [tokenizer.tokenize(seq) for seq in seq_bert]\n",
    "    labels = [label2id[x] for x in labels]\n",
    "\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')\n",
    "\n",
    "    attention_masks = []\n",
    "\n",
    "    for seq in tqdm(input_ids):\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "1ZoBA7L8JQm6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31720/31720 [00:03<00:00, 8393.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# rand_idx = np.random.choice(range(len(gt_test_labels)),10)\n",
    "\n",
    "tt = np.array(gt_test_texts)#[rand_idx]\n",
    "tl = np.array(gt_test_labels)#[rand_idx]\n",
    "\n",
    "test_input, test_attention_mask, test_label = seqs2input(\n",
    "    tt,\n",
    "    tl,\n",
    "    MAX_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input=test_input.to(device)\n",
    "test_attention_mask=test_attention_mask.to(device)\n",
    "test_label=test_label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"예측 값:\", pred_label)\n",
    "print(\"실제 값:\", test_label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txz6hItVZndy"
   },
   "source": [
    "For Many Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "uJpF1HxKYHMF"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40\n",
    "\n",
    "test_data = TensorDataset(test_input, test_attention_mask, test_label)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 434/793 [01:27<01:12,  4.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(b_input_ids,\n\u001b[1;32m     11\u001b[0m              token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m              attention_mask\u001b[38;5;241m=\u001b[39mb_input_mask)\n\u001b[1;32m     14\u001b[0m logits \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     16\u001b[0m label_ids \u001b[38;5;241m=\u001b[39m b_labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     18\u001b[0m tmp_eval_accuracy \u001b[38;5;241m=\u001b[39m flat_accuracy(logits, label_ids)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_accuracy = 0\n",
    "nb_eval_steps = 0\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(b_input_ids,\n",
    "                     token_type_ids=None,\n",
    "                     attention_mask=b_input_mask)\n",
    "\n",
    "        logits = pred[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "\n",
    "print(\"Test Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [02:46<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "eval_accuracy = 0\n",
    "nb_eval_steps = 0\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(b_input_ids,\n",
    "                     token_type_ids=None,\n",
    "                     attention_mask=b_input_mask)\n",
    "\n",
    "        logits = pred[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "\n",
    "print(\"Test Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "team_conda",
   "language": "python",
   "name": "team_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
